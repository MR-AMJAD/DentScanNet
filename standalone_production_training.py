import os
import argparse
import json
import tensorflow as tf
from tensorflow.keras import layers, models, mixed_precision
import numpy as np
import pandas as pd
from datetime import datetime
import time
from concurrent.futures import ThreadPoolExecutor

# Try OpenCV for point dilation
try:
    import cv2
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False
    print("Warning: OpenCV not available, using numpy fallback for point dilation")

# ============================================================================
# CONFIGURATION
# ============================================================================

mixed_precision.set_global_policy('mixed_float16')

# Dataset configuration
IMAGE_HEIGHT = 256
IMAGE_WIDTH = 256
NUM_CLASSES = 2

# Features
ALL_FEATURES = ['GM', 'CEJ', 'ABC', 'TOOTH', 'BONE', 'GINGIVA']
POINT_FEATURES = ['GM', 'CEJ', 'ABC']
REGION_FEATURES = ['TOOTH', 'BONE', 'GINGIVA']

print("="*80)
print("STANDALONE PRODUCTION MODEL TRAINING")
print("="*80)
print("Architecture: Stable Reparam + SSM V1 + Optimized Pyramid")
print("Expected Performance: 66.01% Avg Dice")
print("Parameters: ~600K")
print("="*80 + "\n")

# ============================================================================
# CORE BUILDING BLOCKS
# ============================================================================

def stable_reparameterizable_block(x, filters, stride=1, training=True, block_id=None):
    """Stable reparameterizable block - CORRECTED to match v7 architecture"""
    if stride > 1:
        x = layers.Conv2D(filters, 3, strides=stride, padding='same',
                         kernel_initializer='he_normal',
                         name=f'{block_id}_stride')(x)
        x = layers.BatchNormalization(name=f'{block_id}_stride_bn')(x)
        x = layers.ReLU(name=f'{block_id}_stride_relu')(x)
    
    # Main path with dilated convolution
    main_path = layers.Conv2D(filters, 3, strides=1, padding='same',
                             dilation_rate=2, kernel_initializer='he_normal',
                             name=f'{block_id}_main')(x)
    main_path = layers.BatchNormalization(name=f'{block_id}_main_bn')(main_path)
    main_path = layers.ReLU(name=f'{block_id}_main_relu')(main_path)
    
    if training:
        # Secondary path only when training (reparameterization)
        secondary_path = layers.Conv2D(filters, 1, strides=1, padding='same',
                                      kernel_initializer='he_normal',
                                      name=f'{block_id}_secondary')(x)
        secondary_path = layers.BatchNormalization(name=f'{block_id}_secondary_bn')(secondary_path)
        secondary_path = layers.ReLU(name=f'{block_id}_secondary_relu')(secondary_path)
        
        # Combine paths with weighted addition for stability
        alpha = 0.7  # Weight for main path
        main_scaled = layers.Lambda(lambda y: alpha * y,
                                   name=f'{block_id}_main_scale')(main_path)
        sec_scaled = layers.Lambda(lambda y: (1-alpha) * y,
                                  name=f'{block_id}_sec_scale')(secondary_path)
        combined = layers.Add(name=f'{block_id}_combine')([main_scaled, sec_scaled])
        
        # Residual connection if dimensions match
        if stride == 1 and x.shape[-1] == filters:
            result = layers.Add(name=f'{block_id}_residual')([x, combined])
            return result
        else:
            return combined
    else:
        # Inference mode - use only main path for speed
        if stride == 1 and x.shape[-1] == filters:
            result = layers.Add(name=f'{block_id}_residual_simple')([x, main_path])
            return result
        else:
            return main_path


def ssm_v1_original(x, hidden_dim, state_dim, block_id):
    """Original SSM V1 - essential for performance"""
    # Project to hidden dimension
    x_proj = layers.Conv2D(hidden_dim, 1, padding='same',
                          kernel_initializer='he_normal',
                          name=f'ssm_proj_{block_id}')(x)
    x_proj = layers.BatchNormalization(name=f'ssm_proj_bn_{block_id}')(x_proj)
    
    # Depthwise convolution
    dw_conv = layers.DepthwiseConv2D(3, padding='same', depth_multiplier=1,
                                    depthwise_initializer='he_normal',
                                    name=f'ssm_dw_{block_id}')(x_proj)
    dw_conv = layers.BatchNormalization(name=f'ssm_dw_bn_{block_id}')(dw_conv)
    dw_conv = layers.ReLU(name=f'ssm_dw_relu_{block_id}')(dw_conv)
    
    # Pointwise convolution
    point_conv = layers.Conv2D(hidden_dim, 1, padding='same',
                              kernel_initializer='he_normal',
                              name=f'ssm_point_{block_id}')(dw_conv)
    point_conv = layers.BatchNormalization(name=f'ssm_point_bn_{block_id}')(point_conv)
    point_conv = layers.ReLU(name=f'ssm_point_relu_{block_id}')(point_conv)
    
    # Global context
    global_context = layers.GlobalAveragePooling2D(keepdims=True,
                                                  name=f'ssm_gap_{block_id}')(x_proj)
    global_context = layers.Conv2D(hidden_dim, 1, padding='same',
                                  kernel_initializer='he_normal',
                                  name=f'ssm_ctx_{block_id}')(global_context)
    
    # Attention mechanism
    attention = layers.Lambda(lambda inputs: tf.nn.sigmoid(
        tf.reduce_sum(inputs[0] * inputs[1], axis=-1, keepdims=True)
    ), name=f'attention_{block_id}')([point_conv, global_context])
    
    # Apply attention
    attended_features = layers.Multiply(name=f'attended_{block_id}')([point_conv, attention])
    
    # Output projection
    output = layers.Conv2D(x.shape[-1], 1, padding='same',
                          kernel_initializer='he_normal',
                          name=f'ssm_out_{block_id}')(attended_features)
    
    # Residual connection with scaling
    output = layers.Lambda(lambda inputs: inputs[0] + 0.3 * inputs[1],
                          name=f'ssm_residual_{block_id}')([x, output])
    
    return output


class OptimizedPyramidPoolingLayer(layers.Layer):
    """Optimized pyramid pooling for multi-scale features"""
    
    def __init__(self, filters=256, pool_sizes=[1, 2, 3, 6], **kwargs):
        super().__init__(**kwargs)
        self.filters = filters
        self.pool_sizes = pool_sizes
        
    def build(self, input_shape):
        # Pooling convolutions
        self.pool_convs = []
        for size in self.pool_sizes[1:]:
            conv = layers.Conv2D(self.filters // len(self.pool_sizes), 1,
                               kernel_initializer='he_normal',
                               name=f'{self.name}_pool_{size}')
            self.pool_convs.append(conv)
        
        # Global pooling
        self.global_conv = layers.Conv2D(self.filters // len(self.pool_sizes), 1,
                                       kernel_initializer='he_normal',
                                       name=f'{self.name}_global')
        
        # Final fusion
        self.final_conv = layers.Conv2D(self.filters, 1,
                                      kernel_initializer='he_normal',
                                      name=f'{self.name}_final')
        self.final_bn = layers.BatchNormalization(name=f'{self.name}_final_bn')
        super().build(input_shape)
        
    def call(self, inputs, training=None):
        input_shape = tf.shape(inputs)
        h, w = input_shape[1], input_shape[2]
        
        pooled_features = [inputs]
        
        # Global average pooling
        global_pool = layers.GlobalAveragePooling2D(keepdims=True)(inputs)
        global_feat = self.global_conv(global_pool)
        global_feat = tf.image.resize(global_feat, [h, w], method='bilinear')
        pooled_features.append(global_feat)
        
        # Multi-scale pooling
        for i, (size, conv) in enumerate(zip(self.pool_sizes[1:], self.pool_convs)):
            pooled = layers.AveragePooling2D(pool_size=size, strides=size, 
                                            padding='same')(inputs)
            pooled = conv(pooled)
            pooled = tf.image.resize(pooled, [h, w], method='bilinear')
            pooled_features.append(pooled)
        
        # Concatenate and fuse
        concat_features = layers.Concatenate(axis=-1)(pooled_features)
        output = self.final_conv(concat_features)
        output = self.final_bn(output, training=training)
        output = layers.ReLU()(output)
        
        return output
    
    def get_config(self):
        config = super().get_config()
        config.update({
            'filters': self.filters,
            'pool_sizes': self.pool_sizes
        })
        return config


# ============================================================================
# LOSS FUNCTIONS & METRICS
# ============================================================================

# ============================================================================
# LOSS FUNCTIONS & METRICS - FIXED FOR TENSORFLOW GRAPH EXECUTION
# ============================================================================

def dice_coefficient_metric(y_true, y_pred, smooth=1e-6):
    """Dice coefficient metric - FIXED for TensorFlow graph execution"""
    y_true = tf.cast(y_true, tf.float32)
    y_pred = tf.cast(y_pred, tf.float32)
    
    # Extract positive class (channel 1) - outputs always have shape [..., 2]
    y_true_f = y_true[..., 1]
    y_pred_f = y_pred[..., 1]
    
    intersection = tf.reduce_sum(y_true_f * y_pred_f)
    union = tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f)
    
    return (2. * intersection + smooth) / (union + smooth)


def centroid_error_loss(y_true, y_pred, smooth=1e-6):
    """Centroid error loss for point features - FIXED for TensorFlow graph execution"""
    y_true = tf.cast(y_true, tf.float32)
    y_pred = tf.cast(y_pred, tf.float32)
    
    # Extract positive class (channel 1) - outputs always have shape [..., 2]
    y_true_positive = y_true[..., 1]
    y_pred_positive = y_pred[..., 1]
    
    # Get spatial dimensions
    y_true_shape = tf.shape(y_true_positive)
    height = tf.cast(y_true_shape[1], tf.float32)
    width = tf.cast(y_true_shape[2], tf.float32)
    
    # Create coordinate grids
    y_coords = tf.range(height, dtype=tf.float32)
    x_coords = tf.range(width, dtype=tf.float32)
    y_grid, x_grid = tf.meshgrid(y_coords, x_coords, indexing='ij')
    
    y_grid = tf.expand_dims(y_grid, 0)
    x_grid = tf.expand_dims(x_grid, 0)
    
    # Calculate centroids
    true_mass = tf.reduce_sum(y_true_positive, axis=[1, 2], keepdims=True) + smooth
    true_centroid_y = tf.reduce_sum(y_true_positive * y_grid, axis=[1, 2]) / tf.squeeze(true_mass)
    true_centroid_x = tf.reduce_sum(y_true_positive * x_grid, axis=[1, 2]) / tf.squeeze(true_mass)
    
    pred_mass = tf.reduce_sum(y_pred_positive, axis=[1, 2], keepdims=True) + smooth
    pred_centroid_y = tf.reduce_sum(y_pred_positive * y_grid, axis=[1, 2]) / tf.squeeze(pred_mass)
    pred_centroid_x = tf.reduce_sum(y_pred_positive * x_grid, axis=[1, 2]) / tf.squeeze(pred_mass)
    
    # Euclidean distance
    centroid_distance = tf.sqrt(
        tf.square(true_centroid_y - pred_centroid_y) + 
        tf.square(true_centroid_x - pred_centroid_x) + 
        smooth
    )
    
    # Normalize by image diagonal
    image_diagonal = tf.sqrt(height * height + width * width)
    normalized_distance = centroid_distance / image_diagonal
    
    return tf.reduce_mean(normalized_distance)


def combined_centroid_dice_loss(y_true, y_pred, alpha=0.7, smooth=1e-6):
    """Combined centroid + dice loss - FIXED for TensorFlow graph execution"""
    centroid_loss = centroid_error_loss(y_true, y_pred, smooth)
    
    y_true = tf.cast(y_true, tf.float32)
    y_pred = tf.cast(y_pred, tf.float32)
    
    # Extract positive class (channel 1) - outputs always have shape [..., 2]
    y_true_positive = y_true[..., 1]
    y_pred_positive = y_pred[..., 1]
    
    intersection = tf.reduce_sum(y_true_positive * y_pred_positive)
    union = tf.reduce_sum(y_true_positive) + tf.reduce_sum(y_pred_positive)
    dice = (2.0 * intersection + smooth) / (union + smooth)
    dice_loss = 1.0 - dice
    
    return alpha * centroid_loss + (1.0 - alpha) * dice_loss


def centroid_distance_metric_fixed(y_true, y_pred):
    """Centroid distance metric in pixels - FIXED for TensorFlow graph execution"""
    y_true = tf.cast(y_true, tf.float32)
    y_pred = tf.cast(y_pred, tf.float32)
    
    # Extract positive class (channel 1) - outputs always have shape [..., 2]
    y_true_positive = y_true[..., 1]
    y_pred_positive = y_pred[..., 1]
    
    y_true_shape = tf.shape(y_true_positive)
    height = tf.cast(y_true_shape[1], tf.float32)
    width = tf.cast(y_true_shape[2], tf.float32)
    
    y_coords = tf.range(height, dtype=tf.float32)
    x_coords = tf.range(width, dtype=tf.float32)
    y_grid, x_grid = tf.meshgrid(y_coords, x_coords, indexing='ij')
    
    y_grid = tf.expand_dims(y_grid, 0)
    x_grid = tf.expand_dims(x_grid, 0)
    
    smooth = 1e-6
    
    true_mass = tf.reduce_sum(y_true_positive, axis=[1, 2], keepdims=True) + smooth
    true_centroid_y = tf.reduce_sum(y_true_positive * y_grid, axis=[1, 2]) / tf.squeeze(true_mass)
    true_centroid_x = tf.reduce_sum(y_true_positive * x_grid, axis=[1, 2]) / tf.squeeze(true_mass)
    
    pred_mass = tf.reduce_sum(y_pred_positive, axis=[1, 2], keepdims=True) + smooth
    pred_centroid_y = tf.reduce_sum(y_pred_positive * y_grid, axis=[1, 2]) / tf.squeeze(pred_mass)
    pred_centroid_x = tf.reduce_sum(y_pred_positive * x_grid, axis=[1, 2]) / tf.squeeze(pred_mass)
    
    centroid_distance = tf.sqrt(
        tf.square(true_centroid_y - pred_centroid_y) + 
        tf.square(true_centroid_x - pred_centroid_x) + 
        smooth
    )
    
    return tf.reduce_mean(centroid_distance)


def create_production_loss_functions(features=ALL_FEATURES, centroid_alpha=0.7):
    """Create optimized loss functions for production model"""
    losses = {}
    loss_weights = {}
    metrics = {}
    
    def create_dice_loss(class_weights):
        def dice_loss_fn(y_true, y_pred):
            y_true = tf.cast(y_true, tf.float32)
            y_pred = tf.cast(y_pred, tf.float32)
            
            total_loss = 0.0
            total_weight = tf.reduce_sum(class_weights)
            
            for class_idx, weight in enumerate(class_weights):
                y_true_class = y_true[..., class_idx]
                y_pred_class = y_pred[..., class_idx]
                
                y_true_flat = tf.reshape(y_true_class, [-1])
                y_pred_flat = tf.reshape(y_pred_class, [-1])
                
                intersection = tf.reduce_sum(y_true_flat * y_pred_flat)
                union = tf.reduce_sum(y_true_flat) + tf.reduce_sum(y_pred_flat)
                
                dice = (2.0 * intersection + 1e-6) / (union + 1e-6)
                dice = tf.clip_by_value(dice, 0.0, 1.0)
                
                total_loss += weight * (1.0 - dice)
            
            return total_loss / total_weight
        
        return dice_loss_fn
    
    for feature in features:
        output_name = f'{feature}_output'
        
        if feature in POINT_FEATURES:
            # Point features: centroid + dice
            def create_centroid_loss(alpha=centroid_alpha):
                def loss_fn(y_true, y_pred):
                    return combined_centroid_dice_loss(y_true, y_pred, alpha=alpha)
                return loss_fn
            
            losses[output_name] = create_centroid_loss(centroid_alpha)
            loss_weights[output_name] = 2.5
            metrics[output_name] = [dice_coefficient_metric, centroid_distance_metric_fixed, 'accuracy']
        else:
            # Region features: weighted dice
            losses[output_name] = create_dice_loss([1.0, 20.0])
            loss_weights[output_name] = 1.0
            metrics[output_name] = [dice_coefficient_metric, 'accuracy']
    
    return losses, loss_weights, metrics
# ============================================================================
# FEATURE HEADS
# ============================================================================

def create_optimized_feature_heads(shared_features, features):
    """Create efficient feature-specific output heads"""
    feature_outputs = {}
    
    # Group by feature type
    point_features = [f for f in features if f in POINT_FEATURES]
    region_features = [f for f in features if f in REGION_FEATURES]
    
    # Point features head
    if point_features:
        point_conv = layers.Conv2D(len(point_features) * 16, 3, padding='same',
                                   kernel_initializer='he_normal',
                                   name='point_features_conv')(shared_features)
        point_conv = layers.BatchNormalization(name='point_features_bn')(point_conv)
        point_conv = layers.ReLU(name='point_features_relu')(point_conv)
        
        for i, feature in enumerate(point_features):
            start_ch = i * 16
            end_ch = (i + 1) * 16
            feature_conv = layers.Lambda(
                lambda x, s=start_ch, e=end_ch: x[..., s:e],
                name=f'{feature}_extract'
            )(point_conv)
            
            feature_output = layers.Conv2D(NUM_CLASSES, 1,
                                          kernel_initializer='glorot_uniform',
                                          name=f'{feature}_logits')(feature_conv)
            feature_output = layers.Activation('softmax', dtype='float32',
                                              name=f'{feature}_output')(feature_output)
            feature_outputs[feature] = feature_output
    
    # Region features head
    if region_features:
        region_conv = layers.Conv2D(len(region_features) * 16, 3, padding='same',
                                    kernel_initializer='he_normal',
                                    name='region_features_conv')(shared_features)
        region_conv = layers.BatchNormalization(name='region_features_bn')(region_conv)
        region_conv = layers.ReLU(name='region_features_relu')(region_conv)
        
        for i, feature in enumerate(region_features):
            start_ch = i * 16
            end_ch = (i + 1) * 16
            feature_conv = layers.Lambda(
                lambda x, s=start_ch, e=end_ch: x[..., s:e],
                name=f'{feature}_extract'
            )(region_conv)
            
            feature_output = layers.Conv2D(NUM_CLASSES, 1,
                                          kernel_initializer='glorot_uniform',
                                          name=f'{feature}_logits')(feature_conv)
            feature_output = layers.Activation('softmax', dtype='float32',
                                              name=f'{feature}_output')(feature_output)
            feature_outputs[feature] = feature_output
    
    return feature_outputs


# ============================================================================
# PRODUCTION MODEL ARCHITECTURE
# ============================================================================

def build_production_model(input_shape=(256, 256, 3), features=ALL_FEATURES, training=True):
    """
    Build the optimal production model - STANDALONE VERSION
    
    Architecture:
    - Stable Reparameterizable Blocks (with training mode support)
    - SSM V1 Original
    - Optimized Pyramid Pooling
    - Concatenate Fusion
    
    Expected: 66.01% Avg Dice | 599,516 parameters
    """
    
    print("\nBuilding Production Model...")
    print(f"Input shape: {input_shape}")
    print(f"Features: {len(features)}")
    print(f"Training mode: {training}")
    
    inputs = layers.Input(input_shape, name='input')
    
    # ========== STEM ==========
    x = layers.Conv2D(32, 3, strides=2, padding='same',
                      kernel_initializer='he_normal', name='stem_conv')(inputs)
    x = layers.BatchNormalization(name='stem_bn')(x)
    x = layers.ReLU(name='stem_relu')(x)
    
    # ========== DETAIL BRANCH ==========
    detail = layers.Conv2D(32, 3, padding='same',
                          kernel_initializer='he_normal', name='detail_conv')(x)
    detail = layers.BatchNormalization(name='detail_bn')(detail)
    detail = layers.ReLU(name='detail_relu')(detail)
    
    # Stable reparam blocks (with training parameter)
    for i in range(2):
        detail = stable_reparameterizable_block(detail, 32, stride=1,
                                               training=training,
                                               block_id=f'detail_block_{i}')
    
    # ========== SEMANTIC BRANCH ==========
    semantic = layers.Conv2D(64, 3, strides=2, padding='same',
                            kernel_initializer='he_normal', name='semantic_conv')(x)
    semantic = layers.BatchNormalization(name='semantic_bn')(semantic)
    semantic = layers.ReLU(name='semantic_relu')(semantic)
    
    semantic = stable_reparameterizable_block(semantic, 64, stride=1,
                                             training=training,
                                             block_id='semantic_1')
    
    # ========== SSM V1 BLOCK 1 ==========
    semantic = ssm_v1_original(semantic, 96, 32, 'ssm_1')
    
    # ========== OPTIMIZED PYRAMID POOLING ==========
    semantic = OptimizedPyramidPoolingLayer(filters=96, name='pyramid_pooling')(semantic)
    
    # ========== CROSS-CONNECTIONS ==========
    semantic_up = layers.Conv2DTranspose(32, 3, strides=2, padding='same',
                                        kernel_initializer='he_normal',
                                        name='cross_up')(semantic)
    semantic_up = layers.Lambda(lambda x: tf.image.resize(
        x[0], tf.shape(x[1])[1:3], method='bilinear'
    ), name='match_shape')([semantic_up, detail])
    
    detail_down = layers.Conv2D(96, 3, strides=2, padding='same',
                               kernel_initializer='he_normal',
                               name='cross_down')(detail)
    detail_down = layers.Lambda(lambda x: tf.image.resize(
        x[0], tf.shape(x[1])[1:3], method='bilinear'
    ), name='match_shape2')([detail_down, semantic])
    
    detail_fused = layers.Add(name='detail_fused')([detail, semantic_up])
    semantic_fused = layers.Add(name='semantic_fused')([semantic, detail_down])
    
    # ========== FINAL PROCESSING ==========
    detail_final = stable_reparameterizable_block(detail_fused, 48, stride=1,
                                                 training=training,
                                                 block_id='detail_final')
    semantic_final = stable_reparameterizable_block(semantic_fused, 96, stride=2,
                                                   training=training,
                                                   block_id='semantic_final')
    
    # ========== SSM V1 BLOCK 2 ==========
    semantic_final = ssm_v1_original(semantic_final, 128, 48, 'ssm_2')
    
    # ========== UPSAMPLING ==========
    semantic_up_final = layers.Conv2DTranspose(48, 3, strides=4, padding='same',
                                              kernel_initializer='he_normal',
                                              name='final_up')(semantic_final)
    
    semantic_up_final = layers.Lambda(lambda x: tf.image.resize(
        x[0], tf.shape(x[1])[1:3], method='bilinear'
    ), name='final_match')([semantic_up_final, detail_final])
    
    # ========== CONCATENATE FUSION ==========
    shared_features = layers.Concatenate(name='shared_concat')([detail_final, semantic_up_final])
    shared_features = layers.Conv2D(64, 3, padding='same',
                                   kernel_initializer='he_normal',
                                   name='shared_conv')(shared_features)
    shared_features = layers.BatchNormalization(name='shared_bn')(shared_features)
    shared_features = layers.ReLU(name='shared_relu')(shared_features)
    
    # ========== FINAL UPSAMPLING ==========
    shared_features = layers.Conv2DTranspose(32, 3, strides=2, padding='same',
                                            kernel_initializer='he_normal',
                                            name='final_upsample')(shared_features)
    shared_features = layers.Lambda(lambda x: tf.image.resize(
        x, [input_shape[0], input_shape[1]], method='bilinear'
    ), name='resize_final')(shared_features)
    
    # ========== OUTPUT HEADS ==========
    feature_outputs = create_optimized_feature_heads(shared_features, features)
    
    model = models.Model(inputs, list(feature_outputs.values()),
                        name='Production_V7_Optimal')
    
    for i, feature in enumerate(features):
        model.output_names[i] = f'{feature}_output'
    
    print(f"‚úì Model built successfully!")
    print(f"  Parameters: {model.count_params():,}")
    print(f"  Expected performance: 66.01% Avg Dice\n")
    
    return model, feature_outputs


# ============================================================================
# DATA LOADER
# ============================================================================

class OptimizedDataLoader:
    """Memory-efficient data loader with point dilation"""
    
    def __init__(self, data_path, features, batch_size, target_size,
                 enable_point_dilation=True, dilation_radius=3, is_training=True):
        self.data_path = data_path
        self.features = features
        self.batch_size = batch_size
        self.target_size = target_size
        self.enable_point_dilation = enable_point_dilation
        self.dilation_radius = dilation_radius
        self.is_training = is_training
        
        self.images_path = os.path.join(data_path, 'images')
        self.masks_path = os.path.join(data_path, 'masks')
        self.image_files = [f for f in os.listdir(self.images_path)
                           if f.endswith(('.png', '.jpg', '.jpeg'))]
        
        self.feature_availability = self._precompute_feature_availability()
        self.executor = ThreadPoolExecutor(max_workers=4)
        
        print(f"Data loader initialized: {len(self.image_files)} files from {data_path}")
    
    def _precompute_feature_availability(self):
        availability = {}
        for filename in self.image_files:
            base_name = os.path.splitext(filename)[0]
            availability[filename] = {}
            for feature in self.features:
                mask_filename = f"{base_name}_{feature}.png"
                mask_path = os.path.join(self.masks_path, mask_filename)
                availability[filename][feature] = os.path.exists(mask_path)
        return availability
    
    def preprocess_mask(self, mask, feature):
        """Preprocess mask with optional point dilation"""
        if mask.max() > 1.0:
            mask = mask / 255.0
        
        mask_binary = (mask > 0.5).astype(np.float32)
        
        # Point dilation for point features
        if feature in POINT_FEATURES and self.enable_point_dilation and np.sum(mask_binary) > 0:
            if CV2_AVAILABLE:
                kernel = cv2.getStructuringElement(
                    cv2.MORPH_ELLIPSE,
                    (self.dilation_radius*2, self.dilation_radius*2)
                )
                mask_binary = cv2.dilate(mask_binary.astype(np.uint8), kernel, iterations=1)
                mask_binary = mask_binary.astype(np.float32)
        
        return mask_binary
    
    def load_sample(self, filename):
        """Load single image and masks"""
        try:
            # Load image
            img_path = os.path.join(self.images_path, filename)
            img = tf.keras.preprocessing.image.load_img(img_path, target_size=self.target_size)
            img = tf.keras.preprocessing.image.img_to_array(img, dtype=np.float32) / 255.0
            
            # Load masks
            base_name = os.path.splitext(filename)[0]
            feature_masks = {}
            
            for feature in self.features:
                if self.feature_availability[filename][feature]:
                    mask_filename = f"{base_name}_{feature}.png"
                    mask_path = os.path.join(self.masks_path, mask_filename)
                    
                    mask = tf.keras.preprocessing.image.load_img(
                        mask_path, target_size=self.target_size, color_mode='grayscale'
                    )
                    mask = tf.keras.preprocessing.image.img_to_array(mask, dtype=np.float32)
                    mask = mask.squeeze()
                    
                    processed_mask = self.preprocess_mask(mask, feature)
                    combined_mask = np.stack([1.0 - processed_mask, processed_mask], axis=-1)
                    feature_masks[feature] = combined_mask.astype(np.float32)
                else:
                    # Missing feature - create empty mask
                    feature_masks[feature] = np.zeros(
                        (*self.target_size, NUM_CLASSES), dtype=np.float32
                    )
                    feature_masks[feature][..., 0] = 1.0
            
            return img, feature_masks
            
        except Exception as e:
            print(f"Error loading {filename}: {e}")
            return None, None
    
    def __call__(self):
        """Generator function"""
        while True:
            if self.is_training:
                np.random.shuffle(self.image_files)
            
            for i in range(0, len(self.image_files), self.batch_size):
                batch_files = self.image_files[i:i + self.batch_size]
                
                # Load samples in parallel
                futures = [self.executor.submit(self.load_sample, f) for f in batch_files]
                
                batch_images = []
                batch_masks = {feature: [] for feature in self.features}
                
                for future in futures:
                    img, masks = future.result()
                    if img is not None:
                        batch_images.append(img)
                        for feature in self.features:
                            batch_masks[feature].append(masks[feature])
                
                if batch_images:
                    batch_images = np.stack(batch_images, axis=0)
                    batch_outputs = tuple([np.stack(batch_masks[feature], axis=0)
                                          for feature in self.features])
                    
                    yield batch_images, batch_outputs


# ============================================================================
# TRAINING FUNCTION
# ============================================================================

def train_production_model(data_dir, output_dir, epochs=50, batch_size=4,
                          learning_rate=1e-4, save_best=True):
    """
    Train the production model - STANDALONE VERSION
    
    Args:
        data_dir: Path to dataset (should contain 'train' and 'test' subdirs)
        output_dir: Where to save model and logs
        epochs: Number of training epochs (default: 50 for best results)
        batch_size: Batch size (default: 4)
        learning_rate: Initial learning rate (default: 1e-4)
        save_best: Save best model based on validation loss
    """
    
    print("="*80)
    print("TRAINING PRODUCTION MODEL")
    print("="*80)
    print(f"Data directory: {data_dir}")
    print(f"Output directory: {output_dir}")
    print(f"Epochs: {epochs}")
    print(f"Batch size: {batch_size}")
    print(f"Learning rate: {learning_rate}")
    print("="*80 + "\n")
    
    os.makedirs(output_dir, exist_ok=True)
    
    # Build model
    model, _ = build_production_model(
        input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 3),
        features=ALL_FEATURES
    )
    
    # Create loss functions
    losses, loss_weights, metrics = create_production_loss_functions(
        ALL_FEATURES, centroid_alpha=0.7
    )
    
    # Optimizer with mixed precision
    optimizer = tf.keras.optimizers.Adam(
        learning_rate=learning_rate,
        beta_1=0.9,
        beta_2=0.999,
        epsilon=1e-7,
        clipnorm=1.0
    )
    optimizer = mixed_precision.LossScaleOptimizer(optimizer)
    
    # Compile
    model.compile(
        optimizer=optimizer,
        loss=losses,
        loss_weights=loss_weights,
        metrics=metrics
    )
    
    print("‚úì Model compiled successfully\n")
    
    # Data loaders
    train_path = os.path.join(data_dir, 'train')
    test_path = os.path.join(data_dir, 'test')
    
    print(f"Loading data from:")
    print(f"  Train: {train_path}")
    print(f"  Test: {test_path}\n")
    
    train_loader = OptimizedDataLoader(
        train_path, ALL_FEATURES, batch_size, (IMAGE_HEIGHT, IMAGE_WIDTH),
        enable_point_dilation=True, dilation_radius=3, is_training=True
    )
    
    test_loader = OptimizedDataLoader(
        test_path, ALL_FEATURES, batch_size, (IMAGE_HEIGHT, IMAGE_WIDTH),
        enable_point_dilation=True, dilation_radius=3, is_training=False
    )
    
    train_steps = max(1, len(train_loader.image_files) // batch_size)
    test_steps = max(1, len(test_loader.image_files) // batch_size)
    
    print(f"Dataset info:")
    print(f"  Train samples: {len(train_loader.image_files)}")
    print(f"  Test samples: {len(test_loader.image_files)}")
    print(f"  Train steps per epoch: {train_steps}")
    print(f"  Test steps per epoch: {test_steps}\n")
    
    # Callbacks
    callbacks = [
        tf.keras.callbacks.ModelCheckpoint(
            os.path.join(output_dir, 'production_model_best.h5'),
            monitor='val_loss',
            save_best_only=save_best,
            mode='min',
            verbose=1,
            save_weights_only=False
        ),
        tf.keras.callbacks.EarlyStopping(
            monitor='val_loss',
            patience=15,
            mode='min',
            verbose=1,
            restore_best_weights=True
        ),
        tf.keras.callbacks.ReduceLROnPlateau(
            monitor='val_loss',
            factor=0.5,
            patience=8,
            verbose=1,
            mode='min',
            min_lr=1e-7
        ),
        tf.keras.callbacks.CSVLogger(
            os.path.join(output_dir, 'production_training_log.csv'),
            append=False
        ),
        tf.keras.callbacks.TensorBoard(
            log_dir=os.path.join(output_dir, 'tensorboard_logs'),
            histogram_freq=0,
            write_graph=False
        )
    ]
    
    # Training
    print("="*80)
    print("STARTING TRAINING")
    print("="*80 + "\n")
    
    start_time = time.time()
    
    history = model.fit(
        train_loader(),
        validation_data=test_loader(),
        epochs=epochs,
        steps_per_epoch=train_steps,
        validation_steps=test_steps,
        callbacks=callbacks,
        verbose=1
    )
    
    training_time = time.time() - start_time
    
    print("\n" + "="*80)
    print("TRAINING COMPLETE")
    print("="*80)
    print(f"Total training time: {training_time/60:.1f} minutes")
    print(f"Time per epoch: {training_time/len(history.history['loss'])/60:.1f} minutes\n")
    
    # Final evaluation
    print("Evaluating final model...")
    results = model.evaluate(test_loader(), steps=test_steps, return_dict=True)
    
    # Extract metrics
    feature_performance = {}
    centroid_errors = {}
    
    for feature in ALL_FEATURES:
        dice_key = f'{feature}_output_dice_coefficient_metric'
        if dice_key in results:
            feature_performance[feature] = results[dice_key]
        
        if feature in POINT_FEATURES:
            centroid_key = f'{feature}_output_centroid_distance_metric_fixed'
            if centroid_key in results:
                centroid_errors[feature] = results[centroid_key]
    
    avg_dice = np.mean(list(feature_performance.values()))
    point_dice = np.mean([feature_performance[f] for f in POINT_FEATURES
                         if f in feature_performance])
    region_dice = np.mean([feature_performance[f] for f in REGION_FEATURES
                          if f in feature_performance])
    avg_centroid = np.mean(list(centroid_errors.values())) if centroid_errors else 0
    
    # Save results
    production_results = {
        'model_name': 'Production V7 Optimal (Standalone)',
        'architecture': {
            'reparam_blocks': 'stable_reparameterizable_block',
            'ssm': 'ssm_v1_original',
            'pyramid': 'OptimizedPyramidPoolingLayer',
            'fusion': 'concatenate_fusion'
        },
        'training': {
            'epochs': len(history.history['loss']),
            'batch_size': batch_size,
            'initial_learning_rate': learning_rate,
            'training_time_minutes': training_time / 60
        },
        'performance': {
            'average_dice': float(avg_dice),
            'average_dice_percent': float(avg_dice * 100),
            'point_dice': float(point_dice),
            'region_dice': float(region_dice),
            'avg_centroid_error': float(avg_centroid),
            'feature_dice_scores': {k: float(v) for k, v in feature_performance.items()},
            'centroid_errors': {k: float(v) for k, v in centroid_errors.items()}
        },
        'model_stats': {
            'total_parameters': model.count_params(),
            'trainable_parameters': sum([tf.keras.backend.count_params(w)
                                         for w in model.trainable_weights])
        },
        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    }
    
    with open(os.path.join(output_dir, 'production_results.json'), 'w') as f:
        json.dump(production_results, f, indent=2)
    
    # Save model architecture
    with open(os.path.join(output_dir, 'model_architecture.json'), 'w') as f:
        json.dump(json.loads(model.to_json()), f, indent=2)
    
    # Print summary
    print("\n" + "="*80)
    print("FINAL RESULTS")
    print("="*80)
    print(f"\nüéØ PERFORMANCE:")
    print(f"   Average Dice: {avg_dice:.4f} ({avg_dice*100:.2f}%)")
    print(f"   Point Features: {point_dice:.4f} ({point_dice*100:.2f}%)")
    print(f"   Region Features: {region_dice:.4f} ({region_dice*100:.2f}%)")
    print(f"   Avg Centroid Error: {avg_centroid:.2f} pixels")
    
    print(f"\nüìä PER-FEATURE PERFORMANCE:")
    for feature in ALL_FEATURES:
        if feature in feature_performance:
            dice_pct = feature_performance[feature] * 100
            print(f"   {feature:8s}: {dice_pct:5.2f}%", end="")
            if feature in centroid_errors:
                print(f"  (centroid: {centroid_errors[feature]:.2f}px)")
            else:
                print()
    
    print(f"\nüíæ SAVED FILES:")
    print(f"   Model: {os.path.join(output_dir, 'production_model_best.h5')}")
    print(f"   Results: {os.path.join(output_dir, 'production_results.json')}")
    print(f"   Training log: {os.path.join(output_dir, 'production_training_log.csv')}")
    print(f"   TensorBoard: {os.path.join(output_dir, 'tensorboard_logs')}")
    
    print("\n" + "="*80)
    print("‚úÖ PRODUCTION MODEL TRAINING COMPLETE!")
    print("="*80)
    
    return model, production_results, history


# ============================================================================
# MAIN
# ============================================================================

if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Train Production V7 Optimal Model - STANDALONE (No External Imports)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Production Model Architecture:
  ‚úì Stable Reparameterizable Blocks (proven best)
  ‚úì SSM V1 Original (essential for performance)
  ‚úì Optimized Pyramid Pooling (multi-scale features)
  ‚úì Concatenate Fusion (simple and effective)

Expected Performance: 66.01% Avg Dice | 599,516 parameters

This is a STANDALONE version with NO external imports required.
All components are self-contained in this single file.

Example usage:
  # Standard training (50 epochs recommended)
  python standalone_production_training.py --data_dir ./data --output_dir ./production_model
  
  # Quick test (10 epochs)
  python standalone_production_training.py --data_dir ./data --output_dir ./production_model --epochs 10
  
  # Custom settings
  python standalone_production_training.py --data_dir ./data --output_dir ./production_model \\
      --epochs 100 --batch_size 8 --learning_rate 5e-5
        """
    )
    
    parser.add_argument("--data_dir", type=str, required=True,
                       help="Path to dataset directory (must contain 'train' and 'test' subdirs)")
    parser.add_argument("--output_dir", type=str, required=True,
                       help="Output directory for model and logs")
    parser.add_argument("--epochs", type=int, default=50,
                       help="Number of training epochs (default: 50)")
    parser.add_argument("--batch_size", type=int, default=4,
                       help="Batch size (default: 4)")
    parser.add_argument("--learning_rate", type=float, default=1e-4,
                       help="Initial learning rate (default: 1e-4)")
    parser.add_argument("--no_save_best", action="store_true",
                       help="Save all epochs instead of only best")
    
    args = parser.parse_args()
    
    # Validate paths
    if not os.path.exists(args.data_dir):
        print(f"‚ùå ERROR: Data directory not found: {args.data_dir}")
        exit(1)
    
    train_path = os.path.join(args.data_dir, 'train')
    test_path = os.path.join(args.data_dir, 'test')
    
    if not os.path.exists(train_path) or not os.path.exists(test_path):
        print(f"‚ùå ERROR: Expected 'train' and 'test' subdirectories in {args.data_dir}")
        exit(1)
    
    print(f"\n{'='*80}")
    print(f"STANDALONE PRODUCTION MODEL TRAINING")
    print(f"{'='*80}")
    print(f"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"Data: {args.data_dir}")
    print(f"Output: {args.output_dir}")
    print(f"Settings: {args.epochs} epochs, batch size {args.batch_size}, LR {args.learning_rate}")
    print(f"{'='*80}\n")
    
    try:
        model, results, history = train_production_model(
            data_dir=args.data_dir,
            output_dir=args.output_dir,
            epochs=args.epochs,
            batch_size=args.batch_size,
            learning_rate=args.learning_rate,
            save_best=not args.no_save_best
        )
        
        print(f"\n‚úÖ SUCCESS! Model saved to: {args.output_dir}")
        print(f"üìà Final Performance: {results['performance']['average_dice_percent']:.2f}% Avg Dice")
        
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Training interrupted by user")
        print("Partial results may be available in the output directory")
        exit(1)
        
    except Exception as e:
        print(f"\n\n‚ùå ERROR: Training failed")
        print(f"Error: {e}")
        import traceback
        traceback.print_exc()
        exit(1)
